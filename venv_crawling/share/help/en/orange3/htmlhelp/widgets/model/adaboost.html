
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=cp1252" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AdaBoost</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="next" title="Curve Fit" href="curvefit.html" />
    <link rel="prev" title="Naive Bayes" href="naivebayes.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="adaboost">
<h1>AdaBoost</h1>
<p>An ensemble meta-algorithm that combines weak learners and adapts to the ‘hardness’ of each training sample.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li>Data: input dataset</li>
<li>Preprocessor: preprocessing method(s)</li>
<li>Learner: learning algorithm</li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li>Learner: AdaBoost learning algorithm</li>
<li>Model: trained model</li>
</ul>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank">AdaBoost</a> (short for “Adaptive boosting”) widget is a machine-learning algorithm, formulated by <a class="reference external" href="https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf" target="_blank">Yoav Freund and Robert Schapire</a>. It can be used with other learning algorithms to boost their performance. It does so by tweaking the weak learners.</p>
<p><strong>AdaBoost</strong> works for both classification and regression.</p>
<p><img alt="../../_images/AdaBoost-stamped.png" src="../../_images/AdaBoost-stamped.png" /></p>
<ol class="simple">
<li>The learner can be given a name under which it will appear in other widgets. The default name is “AdaBoost”.</li>
<li>Set the parameters. The base estimator is a tree and you can set:<ul>
<li><em>Number of estimators</em></li>
<li><em>Learning rate</em>: it determines to what extent the newly acquired information will override the old information (0 = the agent will not learn anything, 1 = the agent considers only the most recent information)</li>
<li><em>Fixed seed for random generator</em>: set a fixed seed to enable reproducing the results.</li>
</ul>
</li>
<li>Boosting method.<ul>
<li><em>Classification algorithm</em> (if classification on input): SAMME (updates base estimator’s weights with classification results) or SAMME.R (updates base estimator’s weight with probability estimates).</li>
<li><em>Regression loss function</em> (if regression on input): Linear (), Square (), Exponential ().</li>
</ul>
</li>
<li>Produce a report.</li>
<li>Click <em>Apply</em> after changing the settings. That will put the new learner in the output and, if the training examples are given, construct a new model and output it as well. To communicate changes automatically tick <em>Apply Automatically</em>.</li>
</ol>
<div class="section" id="preprocessing">
<h2>Preprocessing</h2>
<p>AdaBoost uses default preprocessing when no other preprocessors are given. It executes them in the following order:</p>
<ul class="simple">
<li>removes instances with unknown target values</li>
<li>continuizes categorical variables (with one-hot-encoding)</li>
<li>removes empty columns</li>
<li>imputes missing values with mean values</li>
</ul>
<p>To remove default preprocessing, connect an empty <a class="reference internal" href="../data/preprocess.html"><span class="doc">Preprocess</span></a> widget to the learner.</p>
</div>
<div class="section" id="examples">
<h2>Examples</h2>
<p>For classification, we loaded the <em>iris</em> dataset. We used <em>AdaBoost</em>, <a class="reference internal" href="tree.html"><span class="doc">Tree</span></a> and <a class="reference internal" href="logisticregression.html"><span class="doc">Logistic Regression</span></a> and evaluated the models’ performance in <a class="reference internal" href="../evaluate/testandscore.html"><span class="doc">Test &amp; Score</span></a>.</p>
<p><img alt="../../_images/AdaBoost-classification.png" src="../../_images/AdaBoost-classification.png" /></p>
<p>For regression, we loaded the <em>housing</em> dataset, sent the data instances to two different models (<strong>AdaBoost</strong> and <a class="reference internal" href="tree.html"><span class="doc">Tree</span></a>) and output them to the <a class="reference internal" href="../evaluate/predictions.html"><span class="doc">Predictions</span></a> widget.</p>
<p><img alt="../../_images/AdaBoost-regression.png" src="../../_images/AdaBoost-regression.png" /></p>
</div>
</div>


          </div>
          
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2015, Orange Data Mining.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/widgets/model/adaboost.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>