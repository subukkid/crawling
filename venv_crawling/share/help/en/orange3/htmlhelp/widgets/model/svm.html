
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=cp1252" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SVM</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="next" title="Linear Regression" href="linearregression.html" />
    <link rel="prev" title="Gradient Boosting" href="gradientboosting.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="svm">
<h1>SVM</h1>
<p>Support Vector Machines map inputs to higher-dimensional feature spaces.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li>Data: input dataset</li>
<li>Preprocessor: preprocessing method(s)</li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li>Learner: linear regression learning algorithm</li>
<li>Model: trained model</li>
<li>Support Vectors: instances used as support vectors</li>
</ul>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Support_vector_machine" target="_blank">Support vector machine</a> (SVM) is a machine learning technique that separates the attribute space with a hyperplane, thus maximizing the margin between the instances of different classes or class values. The technique often yields supreme predictive performance results. Orange embeds a popular implementation of SVM from the <a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank">LIBSVM</a> package. This widget is its graphical user interface.</p>
<p>For regression tasks, <strong>SVM</strong> performs linear regression in a high dimension feature space using an &#949;-insensitive loss. Its estimation accuracy depends on a good setting of C, &#949; and kernel parameters. The widget outputs class predictions based on a <a class="reference external" href="https://en.wikipedia.org/wiki/Support_vector_machine#Regression" target="_blank">SVM Regression</a>.</p>
<p>The widget works for both classification and regression tasks.</p>
<p><img alt="../../_images/SVM-stamped.png" src="../../_images/SVM-stamped.png" /></p>
<ol class="simple">
<li>The learner can be given a name under which it will appear in other widgets. The default name is “SVM”.</li>
<li>SVM type with test error settings. <em>SVM</em> and <em>&#957;-SVM</em> are based on different minimization of the error function. On the right side, you can set test error bounds:<ul>
<li><a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html" target="_blank">SVM</a>:<ul>
<li><a class="reference external" href="http://www.quora.com/What-are-C-and-gamma-with-regards-to-a-support-vector-machine" target="_blank">Cost</a>: penalty term for loss and applies for classification and regression tasks.</li>
<li>&#949;: a parameter to the epsilon-SVR model, applies to regression tasks. Defines the distance from true values within which no penalty is associated with predicted values.</li>
</ul>
</li>
<li><a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" target="_blank">&#957;-SVM</a>:<ul>
<li><a class="reference external" href="http://www.quora.com/What-are-C-and-gamma-with-regards-to-a-support-vector-machine" target="_blank">Cost</a>: penalty term for loss and applies only to regression tasks</li>
<li>&#957;: a parameter to the &#957;-SVR model, applies to classification and regression tasks. An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.</li>
</ul>
</li>
</ul>
</li>
<li>Kernel is a function that transforms attribute space to a new feature space to fit the maximum-margin hyperplane, thus allowing the algorithm to create the model with <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_model" target="_blank">Linear</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Polynomial_kernel" target="_blank">Polynomial</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel" target="_blank">RBF</a> and <a class="reference external" href="http://crsouza.com/2010/03/kernel-functions-for-machine-learning-applications/#sigmoid" target="_blank">Sigmoid</a> kernels. Functions that specify the kernel are presented upon selecting them, and the constants involved are:<ul>
<li><strong>g</strong> for the gamma constant in kernel function (the recommended value is 1/k, where k is the number of the attributes, but since there may be no training set given to the widget the default is 0 and the user has to set this option manually),</li>
<li><strong>c</strong> for the constant c0 in the kernel function (default 0), and</li>
<li><strong>d</strong> for the degree of the kernel (default 3).</li>
</ul>
</li>
<li>Set permitted deviation from the expected value in <em>Numerical Tolerance</em>. Tick the box next to <em>Iteration Limit</em> to set the maximum number of iterations permitted.</li>
<li>Produce a report.</li>
<li>Click <em>Apply</em> to commit changes. If you tick the box on the left side of the <em>Apply</em> button, changes will be communicated automatically.</li>
</ol>
<div class="section" id="preprocessing">
<h2>Preprocessing</h2>
<p>SVM uses default preprocessing when no other preprocessors are given. It executes them in the following order:</p>
<ul class="simple">
<li>removes instances with unknown target values</li>
<li>continuizes categorical variables (with one-hot-encoding)</li>
<li>removes empty columns</li>
<li>imputes missing values with mean values</li>
</ul>
<p>For classification, SVM also normalizes dense and scales sparse data.</p>
<p>To remove default preprocessing, connect an empty <a class="reference internal" href="../data/preprocess.html"><span class="doc">Preprocess</span></a> widget to the learner.</p>
</div>
<div class="section" id="examples">
<h2>Examples</h2>
<p>In the first (regression) example, we have used <em>housing</em> dataset and split the data into two data subsets (<em>Data Sample</em> and <em>Remaining Data</em>) with <a class="reference internal" href="../data/datasampler.html"><span class="doc">Data Sampler</span></a>. The sample was sent to SVM which produced a <em>Model</em>, which was then used in <a class="reference internal" href="../evaluate/predictions.html"><span class="doc">Predictions</span></a> to predict the values in <em>Remaining Data</em>. A similar schema can be used if the data is already in two separate files; in this case, two <a class="reference internal" href="../data/file.html"><span class="doc">File</span></a> widgets would be used instead of the <a class="reference internal" href="../data/file.html"><span class="doc">File</span></a> - <a class="reference internal" href="../data/datasampler.html"><span class="doc">Data Sampler</span></a> combination.</p>
<p><img alt="../../_images/SVM-Predictions.png" src="../../_images/SVM-Predictions.png" /></p>
<p>The second example shows how to use <strong>SVM</strong> in combination with <a class="reference internal" href="../visualize/scatterplot.html"><span class="doc">Scatter Plot</span></a>. The following workflow trains a SVM model on <em>iris</em> data and outputs support vectors, which are those data instances that were used as support vectors in the learning phase. We can observe which are these data instances in a scatter plot visualization. Note that for the workflow to work correctly, you must set the links between widgets as demonstrated in the screenshot below.</p>
<p><img alt="../../_images/SVM-support-vectors.png" src="../../_images/SVM-support-vectors.png" /></p>
</div>
<div class="section" id="references">
<h2>References</h2>
<p><a class="reference external" href="http://www.statsoft.com/Textbook/Support-Vector-Machines" target="_blank">Introduction to SVM on StatSoft</a>.</p>
</div>
</div>


          </div>
          
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2015, Orange Data Mining.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/widgets/model/svm.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>