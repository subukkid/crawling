
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=cp1252" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CN2 Rule Induction</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="next" title="Calibrated Learner" href="calibratedlearner.html" />
    <link rel="prev" title="Constant" href="constant.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="cn2-rule-induction">
<h1>CN2 Rule Induction</h1>
<p>Induce rules from data using CN2 algorithm.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li>Data: input dataset</li>
<li>Preprocessor: preprocessing method(s)</li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li>Learner: CN2 learning algorithm</li>
<li>CN2 Rule Classifier: trained model</li>
</ul>
<p>The CN2 algorithm is a classification technique designed for the efficient induction of simple, comprehensible rules of form “if <em>cond</em> then predict <em>class</em>”, even in domains where noise may be present.</p>
<p><strong>CN2 Rule Induction</strong> works only for classification.</p>
<p><img alt="../../_images/CN2-stamped.png" src="../../_images/CN2-stamped.png" /></p>
<ol class="simple">
<li>Name under which the learner appears in other widgets. The default name is <em>CN2 Rule Induction</em>.</li>
<li><em>Rule ordering</em>:<ul>
<li><strong>Ordered</strong>: induce ordered rules (decision list). Rule conditions are found and the majority class is assigned in the rule head.</li>
<li><strong>Unordered</strong>: induce unordered rules (rule set). Learn rules for each class individually, in regard to the original learning data.</li>
</ul>
</li>
<li><em>Covering algorithm</em>:<ul>
<li><strong>Exclusive</strong>: after covering a learning instance, remove it from further consideration.</li>
<li><strong>Weighted</strong>: after covering a learning instance, decrease its weight (multiplication by <em>gamma</em>) and in-turn decrease its impact on further iterations of the algorithm.</li>
</ul>
</li>
<li><em>Rule search</em>:<ul>
<li><strong>Evaluation measure</strong>: select a heuristic to evaluate found hypotheses:<ul>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" target="_blank">Entropy</a> (measure of unpredictability of content)</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Laplace%27s_method" target="_blank">Laplace Accuracy</a></li>
<li>Weighted Relative Accuracy</li>
</ul>
</li>
<li><strong>Beam width</strong>; remember the best rule found thus far and monitor a fixed number of alternatives (the beam).</li>
</ul>
</li>
<li><em>Rule filtering</em>:<ul>
<li><strong>Minimum rule coverage</strong>: found rules must cover at least the minimum required number of covered examples. Unordered rules must cover this many target class examples.</li>
<li><strong>Maximum rule length</strong>: found rules may combine at most the maximum allowed number of selectors (conditions).</li>
<li><strong>Default alpha</strong>: significance testing to prune out most specialised (less frequently applicable) rules in regard to the initial distribution of classes.</li>
<li><strong>Parent alpha</strong>: significance testing to prune out most specialised (less frequently applicable) rules in regard to the parent class distribution.</li>
</ul>
</li>
<li>Tick ‘Apply Automatically’ to auto-communicate changes to other widgets and to immediately train the classifier if learning data is connected. Alternatively, press ‘Apply‘ after configuration.</li>
</ol>
<div class="section" id="preprocessing">
<h2>Preprocessing</h2>
<p>CN2 Rule Induction uses default preprocessing when no other preprocessors are given. It executes them in the following order:</p>
<ul class="simple">
<li>removes empty columns</li>
<li>removes instances with unknown target values</li>
<li>imputes missing values with mean values</li>
</ul>
<p>To remove default preprocessing, connect an empty <a class="reference internal" href="../data/preprocess.html"><span class="doc">Preprocess</span></a> widget to the learner.</p>
</div>
<div class="section" id="examples">
<h2>Examples</h2>
<p>For the example below, we have used <em>zoo</em> dataset and passed it to <strong>CN2 Rule Induction</strong>. We can review and interpret the built model with <a class="reference internal" href="../visualize/cn2ruleviewer.html"><span class="doc">CN2 Rule Viewer</span></a> widget.</p>
<p><img alt="../../_images/CN2-visualize.png" src="../../_images/CN2-visualize.png" /></p>
<p>The second workflow tests evaluates <strong>CN2 Rule Induction</strong> and <a class="reference internal" href="tree.html"><span class="doc">Tree</span></a> in <a class="reference internal" href="../evaluate/testandscore.html"><span class="doc">Test &amp; Score</span></a>.</p>
<p><img alt="../../_images/CN2-classification.png" src="../../_images/CN2-classification.png" /></p>
</div>
<div class="section" id="references">
<h2>References</h2>
<ol class="simple">
<li>Fürnkranz, Johannes. “Separate-and-Conquer Rule Learning”, Artificial Intelligence Review 13, 3-54, 1999.</li>
<li>Clark, Peter and Tim Niblett. “The CN2 Induction Algorithm”, Machine Learning Journal, 3 (4), 261-283, 1989.</li>
<li>Clark, Peter and Robin Boswell. “Rule Induction with CN2: Some Recent Improvements”, Machine Learning - Proceedings of the 5th European Conference (EWSL-91),151-163, 1991.</li>
<li>Lavra&#269;, Nada et al. “Subgroup Discovery with CN2-SD”,Journal of Machine Learning Research 5, 153-188, 2004</li>
</ol>
</div>
</div>


          </div>
          
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2015, Orange Data Mining.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/widgets/model/cn2ruleinduction.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>